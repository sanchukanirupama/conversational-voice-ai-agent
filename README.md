# ğŸ™ï¸ AI Voice Banking Agent

A full-stack AI-powered voice banking assistant built with **Next.js**, **FastAPI**, **LangGraph**, and **OpenAI**. The agent handles real-time voice conversations, processes banking requests, and autonomously resolves customer issues using intelligent tool selection.

![Architecture](https://img.shields.io/badge/Architecture-LangGraph-blue)
![Frontend](https://img.shields.io/badge/Frontend-Next.js%2016-black)
![Backend](https://img.shields.io/badge/Backend-FastAPI-green)
![AI](https://img.shields.io/badge/AI-OpenAI-orange)

---

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Architecture](#-architecture)
- [Tech Stack](#-tech-stack)
- [Quick Start](#-quick-start)
- [How It Works](#-how-it-works)
- [LangGraph Flow](#-langgraph-flow)
- [LangSmith Observability](#-langsmith-observability)
- [Project Structure](#-project-structure)
- [Configuration](#-configuration)
- [Development](#-development)

---

## âœ¨ Features

### Voice Capabilities
- ğŸ¤ **Voice Activity Detection (VAD)** - Intelligent speech detection with automatic silence handling
- ğŸ—£ï¸ **Real-time STT** - OpenAI Whisper for accurate transcription

### Banking Features
- ğŸ’³ **Card Management** - Block/freeze cards, report lost/stolen
- ğŸ’° **Account Services** - Balance checks, transaction history
- ğŸ” **Identity Verification** - Secure customer authentication
- ğŸ“ **Address Updates** - Profile management
- ğŸ“ **Smart Call Routing** - Intent classification and flow routing
- ğŸ¤– **Autonomous Problem Solving** - Agent uses tools to resolve issues

### Agent Intelligence
- ğŸ§  **LangGraph Orchestration** - Stateful conversation flow
- ğŸ› ï¸ **Tool-based Actions** - Real database operations via LangChain tools
- ğŸ¯ **Context-aware Routing** - Dynamic flow selection based on user intent
- ğŸ“Š **LangSmith Tracing** - Full observability into agent decisions

---

## ğŸ—ï¸ Architecture

### Communication Flow

```
1. User Speech Detection (Frontend)
   â†“
2. VAD captures audio â†’ Base64 encoding
   â†“
3. WebSocket sends audio to backend
   â†“
4. OpenAI Whisper transcribes audio
   â†“
5. LangGraph Agent processes request
   â”‚
   â”œâ”€â–¶ Router Node: Classify intent
   â”œâ”€â–¶ Gate Node: Check verification status
   â”œâ”€â–¶ Executor Node: Generate response + tool calls
   â””â”€â–¶ Tool Node: Execute actions (DB queries, card blocking, etc.)
   â†“
6. OpenAI TTS generates audio response
   â†“
7. WebSocket sends audio back to frontend
   â†“
8. Frontend plays audio â†’ VAD resumes listening
```

---

## ğŸ› ï¸ Tech Stack

### Frontend
- **Framework**: Next.js 16 (React 19, TypeScript)
- **UI**: Tailwind CSS 4, Framer Motion
- **Audio**: Web Audio API, MediaRecorder API
- **WebSocket**: Native WebSocket API

### Backend
- **Framework**: FastAPI
- **AI Orchestration**: LangGraph
- **LLM**: OpenAI GPT-4
- **Voice**: OpenAI Whisper (STT) + TTS
- **Database**: SQLite
- **Observability**: LangSmith


---

## ğŸš€ Quick Start

### Prerequisites

- **Node.js** 18+ and npm
- **Python** 3.11+
- **OpenAI API Key** ([Get one here](https://platform.openai.com/api-keys))
- **LangSmith API Key** (Optional, for observability - [Sign up here](https://smith.langchain.com/))

### 1. Clone the Repository

```bash
git clone <repository-url>
cd voice-ai-agent
```

### 2. Backend Setup

```bash
# Navigate to backend
cd backend

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment variables
cp .env.example .env

# Edit .env and add your API keys:
# OPENAI_API_KEY=sk-...
# LANGCHAIN_API_KEY=lsv2_...  (optional)
# LANGCHAIN_TRACING_V2=true   (optional)
```

### 3. Frontend Setup

```bash
# Open a new terminal
cd client

# Install dependencies
npm install

# Configure environment (if needed)
cp .env.example .env.local

# Edit .env.local if you need to change the backend URL
# NEXT_PUBLIC_WS_URL=ws://localhost:8000
```

### 4. Run Both Services

**Terminal 1 - Backend:**
```bash
cd backend
source venv/bin/activate
uvicorn backend.main:app --host 0.0.0.0 --port 8000 --reload
```

**Terminal 2 - Frontend:**
```bash
cd client
npm run dev
```

### 5. Open the Application

ğŸŒ **Frontend**: [http://localhost:3000](http://localhost:3000)

ğŸ”§ **Backend API**: [http://localhost:8000/docs](http://localhost:8000/docs)

ğŸ“Š **Admin Dashboard**: [http://localhost:3000/admin/login](http://localhost:3000/admin/login)
- Username: `admin`
- Password: `admin123`

---

## ğŸ”„ How It Works

### Voice Input Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. VAD (Voice Activity Detection)                          â”‚
â”‚     â€¢ Analyzes audio frequency in real-time (60fps)         â”‚
â”‚     â€¢ Threshold: Volume > 40 (0-255 scale)                  â”‚
â”‚     â€¢ Detects speech start automatically                    â”‚
â”‚     â€¢ Waits 1 second of silence before finalizing           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Audio Capture & Encoding                                â”‚
â”‚     â€¢ MediaRecorder captures WebM audio                     â”‚
â”‚     â€¢ Minimum duration: 800ms                               â”‚
â”‚     â€¢ Minimum size: 3000 bytes                              â”‚
â”‚     â€¢ Converts to Base64 data URL                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. WebSocket Transmission                                  â”‚
â”‚     â€¢ Sends: { type: "audio", data: "data:audio/webm..." } â”‚
â”‚     â€¢ Frontend â†’ Backend via WS connection                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Speech-to-Text (Backend)                                â”‚
â”‚     â€¢ OpenAI Whisper API transcription                      â”‚
â”‚     â€¢ Hallucination filtering (removes "Thanks for          â”‚
â”‚       watching!", etc.)                                     â”‚
â”‚     â€¢ Minimum audio size: 1000 bytes                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. LangGraph Agent Processing (See detailed flow below)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. Text-to-Speech                                          â”‚
â”‚     â€¢ OpenAI TTS with "alloy" voice                         â”‚
â”‚     â€¢ Base64 encoded MP3                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. Audio Playback & VAD Resume                             â”‚
â”‚     â€¢ Frontend decodes and plays audio                      â”‚
â”‚     â€¢ VAD gate opens when playback ends                     â”‚
â”‚     â€¢ Listens for next user input                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  LangGraph Flow

### Agent Architecture

The agent uses **LangGraph** to orchestrate a stateful conversation flow with multiple decision nodes:

```
                    START
                      â”‚
                      â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     Router Node         â”‚
        â”‚  â€¢ Classifies user      â”‚
        â”‚    intent using LLM     â”‚
        â”‚  â€¢ Returns flow name    â”‚
        â”‚    (card_atm_issues,    â”‚
        â”‚     account_servicing,  â”‚
        â”‚     general, etc.)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Verification Gate     â”‚
        â”‚  â€¢ Checks if flow       â”‚
        â”‚    requires ID verify   â”‚
        â”‚  â€¢ If required & not    â”‚
        â”‚    verified â†’ injects   â”‚
        â”‚    verification prompt  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    Flow Executor        â”‚
        â”‚  â€¢ Selects tools for    â”‚
        â”‚    the current flow     â”‚
        â”‚  â€¢ Binds system prompt  â”‚
        â”‚  â€¢ Generates response   â”‚
        â”‚  â€¢ May call tools       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
                  Decision
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                   â”‚
         Tools?               No Tools
            â”‚                   â”‚
            â–¼                   â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          END
     â”‚ Tool Node  â”‚
     â”‚ â€¢ Executes â”‚
     â”‚   tools    â”‚
     â”‚ â€¢ Returns  â”‚
     â”‚   results  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â””â”€â”€â”€â”€â”€â”€â–¶ Loop back to Router
```

### Routing Flows

The system supports multiple conversation flows:

1. **card_atm_issues** - Card blocking, lost/stolen reports
2. **account_servicing** - Balance checks, statements
3. **account_opening** - New account inquiries (escalates to human)
4. **digital_app_support** - App login issues (escalates)
5. **transfers_payments** - Payment issues (escalates)
6. **account_closure** - Closure requests (escalates)
7. **general** - Greetings, unclear intent

Each flow has:
- **Required tools**: Available actions for the agent
- **Verification requirement**: Whether ID check is mandatory
- **Max questions**: Escalation threshold
- **Flow instructions**: Specific conversation patterns

---

## ğŸ“Š LangSmith Observability

LangSmith provides full visibility into agent behavior:

### Setup

1. **Create Account**: [smith.langchain.com](https://smith.langchain.com/)

2. **Get API Key**:
   - Settings â†’ API Keys â†’ Create Service API Key
   - Copy the key (starts with `lsv2_...`)

3. **Configure Backend**:
   ```bash
   # backend/.env
   LANGCHAIN_API_KEY=lsv2_...
   LANGCHAIN_TRACING_V2=true
   LANGCHAIN_PROJECT=Voice-Agent-Bank-ABC
   ```

4. **Restart Backend**:
   ```bash
   uvicorn backend.main:app --reload
   ```


---

## ğŸ“ Project Structure

```
voice-ai-agent/
â”‚
â”œâ”€â”€ backend/                      # Python FastAPI backend
â”‚   â”œâ”€â”€ agent/                    # LangGraph agent logic
â”‚   â”‚   â”œâ”€â”€ config.py            # Flow configuration loader
â”‚   â”‚   â”œâ”€â”€ graph.py             # LangGraph workflow builder
â”‚   â”‚   â”œâ”€â”€ nodes.py             # Router, Gate, Executor nodes
â”‚   â”‚   â”œâ”€â”€ state.py             # AgentState type definition
â”‚   â”‚   â””â”€â”€ tools_registry.py   # Tool definitions & registry
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/                  # FastAPI endpoints
â”‚   â”‚   â”œâ”€â”€ websocket.py        # WebSocket handler
â”‚   â”‚   â”œâ”€â”€ admin.py            # Admin API endpoints
â”‚   â”‚   â””â”€â”€ health.py           # Health check
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                # Business logic
â”‚   â”‚   â”œâ”€â”€ audio.py            # STT/TTS with OpenAI
â”‚   â”‚   â””â”€â”€ router.py           # Intent classification
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                    # Configuration & database
â”‚   â”‚   â”œâ”€â”€ unified_configuration.json  # Agent prompts & flows
â”‚   â”‚   â””â”€â”€ voice_agent.db      # SQLite database
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                   # Database operations
â”‚   â”‚   â””â”€â”€ db_operations.py
â”‚   â”‚
â”‚   â”œâ”€â”€ config.py               # Settings management
â”‚   â”œâ”€â”€ main.py                 # FastAPI app entry point
â”‚   â””â”€â”€ requirements.txt        # Python dependencies
â”‚
â”œâ”€â”€ client/                      # Next.js frontend
â”‚   â”œâ”€â”€ app/                     # Next.js 13+ app directory
â”‚   â”‚   â”œâ”€â”€ hooks/              # React hooks
â”‚   â”‚   â”‚   â”œâ”€â”€ useVoiceAgent.ts      # Main WebSocket logic
â”‚   â”‚   â”‚   â””â”€â”€ useAudioRecorder.ts   # VAD engine
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ components/         # React components
â”‚   â”‚   â”‚   â””â”€â”€ VoiceOrb.tsx   # Voice visualization
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ admin/              # Admin dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ login/
â”‚   â”‚   â”‚   â””â”€â”€ dashboard/
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ page.tsx            # Main voice UI
â”‚   â”‚   â””â”€â”€ layout.tsx          # Root layout
â”‚   â”‚
â”‚   â”œâ”€â”€ components/ui/          # UI components
â”‚   â”‚   â”œâ”€â”€ siri-waveform.tsx  # Audio visualization
â”‚   â”‚   â””â”€â”€ retro-grid.tsx     # Background effect
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                   # Helper functions
â”‚   â”‚   â””â”€â”€ audio.ts            # Audio utilities
â”‚   â”‚
â”‚   â””â”€â”€ package.json            # Node dependencies
â”‚
â””â”€â”€ README.md                    # This file
```

---

## âš™ï¸ Configuration

### Backend Environment Variables

```bash
# backend/.env

# Required
OPENAI_API_KEY=sk-...                    # OpenAI API key

# Optional - LangSmith Observability
LANGCHAIN_API_KEY=lsv2_...               # LangSmith API key
LANGCHAIN_TRACING_V2=true                # Enable tracing
LANGCHAIN_PROJECT=Voice-Agent-Bank-ABC   # Project name

# Voice Settings
STT_MODEL=whisper-1                      # Speech-to-text model
STT_LANGUAGE=en                          # Language code
TTS_MODEL=tts-1                          # Text-to-speech model
TTS_VOICE=alloy                          # Voice selection
```

### Frontend Environment Variables

```bash
# client/.env.local

NEXT_PUBLIC_WS_URL=ws://localhost:8000   # Backend WebSocket URL
```

### Agent Configuration

Edit `backend/data/unified_configuration.json` to customize:

- System prompts and personality
- Routing flows and tools
- Verification prompts
- Escalation strategies
- Flow-specific instructions

---

## ğŸ”§ Development

### Running in Development Mode

```bash
# Backend (with auto-reload)
cd backend
uvicorn backend.main:app --reload

# Frontend (with hot reload)
cd client
npm run dev
```

### Testing Voice Features

1. **Microphone Access**: Browser will prompt on first visit
2. **Click the microphone button** to start a call
3. **Speak clearly** - VAD will detect speech automatically
4. **Wait 1 second after speaking** - Automatic silence detection
5. **Watch the console** - Logs show VAD events and transcripts

### Common VAD Parameters (Tunable)

```typescript
// client/app/hooks/useAudioRecorder.ts

const THRESHOLD = 40;           // Volume threshold (0-255)
const SILENCE_DURATION = 1000;  // ms silence before finalizing
const MIN_SPEECH_DURATION = 800; // Minimum speech duration
const MIN_BLOB_SIZE = 3000;     // Minimum audio size (bytes)
```

---

## ğŸ‘¨â€ğŸ’» Author

**Sanchuka Nirupama**
